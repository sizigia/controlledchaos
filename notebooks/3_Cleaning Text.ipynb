{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import spacy\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/text_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder</th>\n",
       "      <th>extension</th>\n",
       "      <th>filename</th>\n",
       "      <th>absolute_path</th>\n",
       "      <th>size_mb</th>\n",
       "      <th>created_on</th>\n",
       "      <th>last_modified_on</th>\n",
       "      <th>unix_permission</th>\n",
       "      <th>raw_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/t5/</td>\n",
       "      <td>.text</td>\n",
       "      <td>000081.text</td>\n",
       "      <td>../data/t5/000081.text</td>\n",
       "      <td>0.013150</td>\n",
       "      <td>2011-02-08 15:37:52</td>\n",
       "      <td>2011-02-08 15:37:52</td>\n",
       "      <td>-rw-r--r--</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/t5/</td>\n",
       "      <td>.text</td>\n",
       "      <td>000083.text</td>\n",
       "      <td>../data/t5/000083.text</td>\n",
       "      <td>0.007671</td>\n",
       "      <td>2011-02-08 15:37:52</td>\n",
       "      <td>2011-02-08 15:37:52</td>\n",
       "      <td>-rw-r--r--</td>\n",
       "      <td>PUBLIC NOTICE\\n FEDERAL COMMUNICATIONS COMMISS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/t5/</td>\n",
       "      <td>.text</td>\n",
       "      <td>000086.text</td>\n",
       "      <td>../data/t5/000086.text</td>\n",
       "      <td>0.026270</td>\n",
       "      <td>2011-02-08 15:37:52</td>\n",
       "      <td>2011-02-08 15:37:52</td>\n",
       "      <td>-rw-r--r--</td>\n",
       "      <td>Time,F-Scale,Location,County,State,Lat,Lon,Com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/t5/</td>\n",
       "      <td>.text</td>\n",
       "      <td>000087.text</td>\n",
       "      <td>../data/t5/000087.text</td>\n",
       "      <td>0.023494</td>\n",
       "      <td>2011-02-08 15:37:52</td>\n",
       "      <td>2011-02-08 15:37:52</td>\n",
       "      <td>-rw-r--r--</td>\n",
       "      <td>**********************************************...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/t5/</td>\n",
       "      <td>.text</td>\n",
       "      <td>000088.text</td>\n",
       "      <td>../data/t5/000088.text</td>\n",
       "      <td>0.004139</td>\n",
       "      <td>2011-02-08 15:37:52</td>\n",
       "      <td>2011-02-08 15:37:52</td>\n",
       "      <td>-rw-r--r--</td>\n",
       "      <td>76                            APPENDIX.\\n able...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        folder extension     filename           absolute_path   size_mb  \\\n",
       "0  ../data/t5/     .text  000081.text  ../data/t5/000081.text  0.013150   \n",
       "1  ../data/t5/     .text  000083.text  ../data/t5/000083.text  0.007671   \n",
       "2  ../data/t5/     .text  000086.text  ../data/t5/000086.text  0.026270   \n",
       "3  ../data/t5/     .text  000087.text  ../data/t5/000087.text  0.023494   \n",
       "4  ../data/t5/     .text  000088.text  ../data/t5/000088.text  0.004139   \n",
       "\n",
       "            created_on     last_modified_on unix_permission  \\\n",
       "0  2011-02-08 15:37:52  2011-02-08 15:37:52      -rw-r--r--   \n",
       "1  2011-02-08 15:37:52  2011-02-08 15:37:52      -rw-r--r--   \n",
       "2  2011-02-08 15:37:52  2011-02-08 15:37:52      -rw-r--r--   \n",
       "3  2011-02-08 15:37:52  2011-02-08 15:37:52      -rw-r--r--   \n",
       "4  2011-02-08 15:37:52  2011-02-08 15:37:52      -rw-r--r--   \n",
       "\n",
       "                                            raw_text  \n",
       "0                                                NaN  \n",
       "1  PUBLIC NOTICE\\n FEDERAL COMMUNICATIONS COMMISS...  \n",
       "2  Time,F-Scale,Location,County,State,Lat,Lon,Com...  \n",
       "3  **********************************************...  \n",
       "4  76                            APPENDIX.\\n able...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filenames without text\n",
    "files_w_text = df[df['raw_text'].isna()]\n",
    "pickle.dump(list(files_w_text['filename'].values), open('../data/file_w_text.pkl', 'wb'))\n",
    "df.drop(index=files_w_text.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "def lemmatizing(text, nlp):\n",
    "    doc = nlp(text.replace('\\n', ' '))\n",
    "    sent = []\n",
    "\n",
    "    for token in doc:\n",
    "        if token.pos_ not in ('PROPN', 'PUNCT', 'NUM', 'SYM'):\n",
    "            if token.lemma_ != '-PRON-':\n",
    "                sent.append(token.lemma_)\n",
    "    \n",
    "    sent = \" \".join(sent).split()\n",
    "    \n",
    "    return \" \".join(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(text):\n",
    "    stemmer = nltk.stem.SnowballStemmer('english', ignore_stopwords=True)\n",
    "    stemmer.stopwords = stopwords.words('english')\n",
    "    \n",
    "    stemmed_words = []\n",
    "    \n",
    "    for w in text.split():\n",
    "        stemmed_words.append(stemmer.stem(w))\n",
    "        \n",
    "    text = ' '.join(stemmed_words)\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmatized_text'] = df['raw_text'].apply(lambda row: lemmatizing(row, nlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stemmed_text'] = df['lemmatized_text'].apply(lambda row: stemming(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/lem_stem_text.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'vectorizer': {\n",
    "        'analyzer': 'word',\n",
    "        'stop_words': stopwords.words('english'),\n",
    "        'ngram_range': (1, 1),\n",
    "        'token_pattern': '[a-z]{3,}',\n",
    "        'min_df': 0.01,\n",
    "        'lowercase': True\n",
    "    },\n",
    "    'raw_documents': df['stemmed_text'],\n",
    "    'components': 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cv = CountVectorizer(**params['vectorizer'])\n",
    "X_cv = cv.fit_transform(raw_documents=params['raw_documents'])\n",
    "\n",
    "cv_doc_word = pd.DataFrame(X_cv.toarray(), columns=cv.get_feature_names())\n",
    "cv_doc_word"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "k = 80\n",
    "U, Sigma, VT = randomized_svd(X_cv, \n",
    "                              n_components=k,\n",
    "                              n_iter=5,\n",
    "                              random_state=None)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(18, 6))\n",
    "plt.title(\"Sigma vs. K Topics\")\n",
    "plt.ylabel(\"Sigma\")\n",
    "plt.xlabel(\"K Topics\")\n",
    "sns.lineplot(range(k), Sigma)\n",
    "plt.savefig(\"sigma_topics_cv.png\");"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "list(zip(Sigma, range(80)))[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>abat</th>\n",
       "      <th>abbrevi</th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>abnorm</th>\n",
       "      <th>aboard</th>\n",
       "      <th>abroad</th>\n",
       "      <th>abrupt</th>\n",
       "      <th>absenc</th>\n",
       "      <th>...</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>yield</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>zero</th>\n",
       "      <th>zinc</th>\n",
       "      <th>zip</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003863</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3248</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3249 rows × 4182 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      abandon  abat  abbrevi  abil       abl  abnorm  aboard  abroad  abrupt  \\\n",
       "0         0.0   0.0      0.0   0.0  0.000000     0.0     0.0     0.0     0.0   \n",
       "1         0.0   0.0      0.0   0.0  0.000000     0.0     0.0     0.0     0.0   \n",
       "2         0.0   0.0      0.0   0.0  0.000000     0.0     0.0     0.0     0.0   \n",
       "3         0.0   0.0      0.0   0.0  0.032074     0.0     0.0     0.0     0.0   \n",
       "4         0.0   0.0      0.0   0.0  0.000000     0.0     0.0     0.0     0.0   \n",
       "...       ...   ...      ...   ...       ...     ...     ...     ...     ...   \n",
       "3244      0.0   0.0      0.0   0.0  0.000000     0.0     0.0     0.0     0.0   \n",
       "3245      0.0   0.0      0.0   0.0  0.003452     0.0     0.0     0.0     0.0   \n",
       "3246      0.0   0.0      0.0   0.0  0.000000     0.0     0.0     0.0     0.0   \n",
       "3247      0.0   0.0      0.0   0.0  0.000000     0.0     0.0     0.0     0.0   \n",
       "3248      0.0   0.0      0.0   0.0  0.000000     0.0     0.0     0.0     0.0   \n",
       "\n",
       "        absenc  ...  yes  yesterday       yet     yield  young  youth  zero  \\\n",
       "0     0.000000  ...  0.0        0.0  0.000000  0.000000    0.0    0.0   0.0   \n",
       "1     0.000000  ...  0.0        0.0  0.009871  0.000000    0.0    0.0   0.0   \n",
       "2     0.000000  ...  0.0        0.0  0.012723  0.000000    0.0    0.0   0.0   \n",
       "3     0.000000  ...  0.0        0.0  0.000000  0.041315    0.0    0.0   0.0   \n",
       "4     0.000000  ...  0.0        0.0  0.000000  0.000000    0.0    0.0   0.0   \n",
       "...        ...  ...  ...        ...       ...       ...    ...    ...   ...   \n",
       "3244  0.017202  ...  0.0        0.0  0.000000  0.008728    0.0    0.0   0.0   \n",
       "3245  0.000000  ...  0.0        0.0  0.000000  0.000000    0.0    0.0   0.0   \n",
       "3246  0.000000  ...  0.0        0.0  0.000000  0.007353    0.0    0.0   0.0   \n",
       "3247  0.000000  ...  0.0        0.0  0.003863  0.000000    0.0    0.0   0.0   \n",
       "3248  0.000000  ...  0.0        0.0  0.000000  0.000000    0.0    0.0   0.0   \n",
       "\n",
       "          zinc  zip      zone  \n",
       "0     0.000000  0.0  0.033480  \n",
       "1     0.000000  0.0  0.000000  \n",
       "2     0.000000  0.0  0.028449  \n",
       "3     0.000000  0.0  0.000000  \n",
       "4     0.000000  0.0  0.000000  \n",
       "...        ...  ...       ...  \n",
       "3244  0.000000  0.0  0.016507  \n",
       "3245  0.000000  0.0  0.000000  \n",
       "3246  0.023367  0.0  0.000000  \n",
       "3247  0.000000  0.0  0.000000  \n",
       "3248  0.000000  0.0  0.000000  \n",
       "\n",
       "[3249 rows x 4182 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(**params['vectorizer'])\n",
    "X_tfidf = tfidf.fit_transform(raw_documents=params['raw_documents'])\n",
    "\n",
    "tfidf_doc_word = pd.DataFrame(X_tfidf.toarray(), columns=tfidf.get_feature_names())\n",
    "tfidf_doc_word"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "k = 80\n",
    "U, Sigma, VT = randomized_svd(X_tfidf, \n",
    "                              n_components=k,\n",
    "                              n_iter=5,\n",
    "                              random_state=None)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(18, 6))\n",
    "plt.title(\"Sigma vs. K Topics\")\n",
    "plt.ylabel(\"Sigma\")\n",
    "plt.xlabel(\"K Topics\")\n",
    "sns.lineplot(range(k), Sigma)\n",
    "plt.savefig(\"sigma_topics_tfidf.png\");"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pair_sig_topic = list(zip(Sigma, range(k)))\n",
    "for i in range(k):\n",
    "    print(pair_sig_topic[i][0])\n",
    "    if str(pair_sig_topic[i][0])[:3] == str(pair_sig_topic[i + 1][0])[:3]:#(pair_sig_topic[i][0] / pair_sig_topic[i + 1][0]) == 1.0:\n",
    "        print(pair_sig_topic[i][0], pair_sig_topic[i + 1][0])\n",
    "        print(pair_sig_topic[i][1], pair_sig_topic[i + 1][1])\n",
    "        print(pair_sig_topic[i + 2])\n",
    "        print(str(pair_sig_topic[i + 2][0])[:3])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: program provid servic child develop plan fund train includ health\n",
      "Topic 1: magnet beam use model corrector measur system temperatur test energi\n",
      "Topic 2: font color decor text famili size none weight background bold\n",
      "Topic 3: por con del que est una persona son sin vez\n",
      "Topic 4: generic drug brand product prescript prefer patent medic name use\n",
      "Topic 5: court appeal claim defend case petition district motion trial attorney\n",
      "Topic 6: water speci plant area habitat soil fish beach site veget\n",
      "Topic 7: file datum inform name use date line number com metadata\n",
      "Topic 8: say get year would work peopl time make like come\n",
      "Topic 9: site displac offset atmospher email load solid alon coordin accord\n",
      "Topic 10: link protein gene genom nucleotid var name cell search cite\n",
      "Topic 11: imag src image gif new button earth mission stereo view\n",
      "Topic 12: shall section requir dwell amend applic cost build person properti\n",
      "Topic 13: locat scan nomin floor zone unit rate hear seri data\n",
      "Topic 14: document function search var els return substring length findobj osrc\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# Use NMF to look for 15 topics\n",
    "n_topics = 15\n",
    "model = NMF(n_components=n_topics)\n",
    "model.fit(X_tfidf)\n",
    "\n",
    "# Print the top 10 words\n",
    "n_words = 10\n",
    "feature_names = tfidf.get_feature_names()\n",
    "\n",
    "topic_list = []\n",
    "for topic_idx, topic in enumerate(model.components_):\n",
    "    top_n = [feature_names[i]\n",
    "             for i in topic.argsort()\n",
    "             [-n_words:]][::-1]\n",
    "    top_features = ' '.join(top_n)\n",
    "    topic_list.append(f\"topic_{'_'.join(top_n[:3])}\") \n",
    "\n",
    "    print(f\"Topic {topic_idx}: {top_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed: 13.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model's Params:  {'learning_decay': 0.5, 'n_components': 5}\n",
      "Best Log Likelihood Score:  -50907.760986031586\n",
      "CPU times: user 9.69 s, sys: 195 ms, total: 9.88 s\n",
      "Wall time: 13min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Beware it will try *all* of the combinations, so it'll take ages\n",
    "search_params = {\n",
    "  'n_components': [5, 10, 15, 20, 25, 30, 40, 50],\n",
    "  'learning_decay': [.2, .5, .7]\n",
    "}\n",
    "\n",
    "# Set up LDA with the options we'll keep static\n",
    "model = LatentDirichletAllocation(learning_method='online')\n",
    "\n",
    "# Try all of the options\n",
    "gridsearch = GridSearchCV(model, param_grid=search_params, n_jobs=-1, verbose=1)\n",
    "gridsearch.fit(X_tfidf)\n",
    "\n",
    "# What did we find?\n",
    "print(\"Best Model's Params: \", gridsearch.best_params_)\n",
    "print(\"Best Log Likelihood Score: \", gridsearch.best_score_)\n",
    "lda_params = gridsearch.best_params_.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_params = gridsearch.best_params_.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: use water speci datum temperatur surfac measur sampl high magnet\n",
      "Topic 1: con por del que est una persona son diabet sin\n",
      "Topic 2: font imag function link var document els color com url\n",
      "Topic 3: altitud unnecessari hatch pore receptor ment airborn ozon extric hinder\n",
      "Topic 4: use provid year cost inform requir drug program includ may\n",
      "CPU times: user 16.4 s, sys: 118 ms, total: 16.5 s\n",
      "Wall time: 18.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Use LDA to look for 5 topics\n",
    "learning_decay, n_topics = lda_params.values()\n",
    "model = LatentDirichletAllocation(learning_method='online', n_components=n_topics, learning_decay=learning_decay)\n",
    "model.fit(X_tfidf)\n",
    "\n",
    "# Print the top 10 words per topic\n",
    "n_words = 10\n",
    "feature_names = tfidf.get_feature_names()\n",
    "\n",
    "topic_list = []\n",
    "for topic_idx, topic in enumerate(model.components_):\n",
    "    top_n = [feature_names[i]\n",
    "             for i in topic.argsort()\n",
    "             [-n_words:]][::-1]\n",
    "    top_features = ' '.join(top_n)\n",
    "    topic_list.append(f\"topic_{'_'.join(top_n[:3])}\") \n",
    "\n",
    "    print(f\"Topic {topic_idx}: {top_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_use_water_speci</th>\n",
       "      <th>topic_con_por_del</th>\n",
       "      <th>topic_font_imag_function</th>\n",
       "      <th>topic_altitud_unnecessari_hatch</th>\n",
       "      <th>topic_use_provid_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.143923</td>\n",
       "      <td>2.016244</td>\n",
       "      <td>2.021396</td>\n",
       "      <td>2.016737</td>\n",
       "      <td>91.801700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63.816697</td>\n",
       "      <td>2.887513</td>\n",
       "      <td>2.742815</td>\n",
       "      <td>2.738853</td>\n",
       "      <td>27.814121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_use_water_speci  topic_con_por_del  topic_font_imag_function  \\\n",
       "0               2.143923           2.016244                  2.021396   \n",
       "1              63.816697           2.887513                  2.742815   \n",
       "\n",
       "   topic_altitud_unnecessari_hatch  topic_use_provid_year  \n",
       "0                         2.016737              91.801700  \n",
       "1                         2.738853              27.814121  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert our counts into numbers\n",
    "amounts = model.transform(X_tfidf) * 100\n",
    "\n",
    "# Set it up as a dataframe\n",
    "topics = pd.DataFrame(amounts, columns=topic_list)\n",
    "topics.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = df['stemmed_text'].index\n",
    "doc_topic = pd.DataFrame(model.fit_transform(tfidf.fit_transform(df['stemmed_text'])).round(5),\n",
    "                         index = label,\n",
    "                         columns=['topic{}'.format(i + 1) for i in range(n_topics)])\n",
    "\n",
    "df['top_topic'] = doc_topic.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02015</td>\n",
       "      <td>0.02016</td>\n",
       "      <td>0.91940</td>\n",
       "      <td>0.02015</td>\n",
       "      <td>0.02015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02739</td>\n",
       "      <td>0.02742</td>\n",
       "      <td>0.88952</td>\n",
       "      <td>0.02829</td>\n",
       "      <td>0.02739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01943</td>\n",
       "      <td>0.01953</td>\n",
       "      <td>0.92218</td>\n",
       "      <td>0.01943</td>\n",
       "      <td>0.01943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01781</td>\n",
       "      <td>0.01781</td>\n",
       "      <td>0.92729</td>\n",
       "      <td>0.01928</td>\n",
       "      <td>0.01781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.04549</td>\n",
       "      <td>0.04547</td>\n",
       "      <td>0.81808</td>\n",
       "      <td>0.04548</td>\n",
       "      <td>0.04549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3655</th>\n",
       "      <td>0.02436</td>\n",
       "      <td>0.02438</td>\n",
       "      <td>0.90254</td>\n",
       "      <td>0.02436</td>\n",
       "      <td>0.02436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3656</th>\n",
       "      <td>0.01895</td>\n",
       "      <td>0.01898</td>\n",
       "      <td>0.92417</td>\n",
       "      <td>0.01896</td>\n",
       "      <td>0.01895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3657</th>\n",
       "      <td>0.02370</td>\n",
       "      <td>0.02370</td>\n",
       "      <td>0.90519</td>\n",
       "      <td>0.02370</td>\n",
       "      <td>0.02370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3658</th>\n",
       "      <td>0.01567</td>\n",
       "      <td>0.01568</td>\n",
       "      <td>0.93729</td>\n",
       "      <td>0.01570</td>\n",
       "      <td>0.01567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3659</th>\n",
       "      <td>0.01946</td>\n",
       "      <td>0.01946</td>\n",
       "      <td>0.92217</td>\n",
       "      <td>0.01946</td>\n",
       "      <td>0.01946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3249 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       topic1   topic2   topic3   topic4   topic5\n",
       "1     0.02015  0.02016  0.91940  0.02015  0.02015\n",
       "2     0.02739  0.02742  0.88952  0.02829  0.02739\n",
       "3     0.01943  0.01953  0.92218  0.01943  0.01943\n",
       "4     0.01781  0.01781  0.92729  0.01928  0.01781\n",
       "5     0.04549  0.04547  0.81808  0.04548  0.04549\n",
       "...       ...      ...      ...      ...      ...\n",
       "3655  0.02436  0.02438  0.90254  0.02436  0.02436\n",
       "3656  0.01895  0.01898  0.92417  0.01896  0.01895\n",
       "3657  0.02370  0.02370  0.90519  0.02370  0.02370\n",
       "3658  0.01567  0.01568  0.93729  0.01570  0.01567\n",
       "3659  0.01946  0.01946  0.92217  0.01946  0.01946\n",
       "\n",
       "[3249 rows x 5 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.91835]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[e for e in doc_topic.iloc[0].values if (e >= doc_topic.iloc[0].values.max() / 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'where'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-5aacd08357ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_topic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ds/lib/python3.8/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_SparseArray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"module 'pandas' has no attribute '{name}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'where'"
     ]
    }
   ],
   "source": [
    "doc_topic.iloc[0].where(doc_topic.iloc[0] > 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute_path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_topic</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>topic1</th>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic2</th>\n",
       "      <td>1025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic4</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic5</th>\n",
       "      <td>2056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           absolute_path\n",
       "top_topic               \n",
       "topic1               106\n",
       "topic2              1025\n",
       "topic4                62\n",
       "topic5              2056"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['top_topic', 'absolute_path']].groupby(by='top_topic').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_topic</th>\n",
       "      <th>absolute_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>topic5</td>\n",
       "      <td>../data/t5/000083.text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>topic2</td>\n",
       "      <td>../data/t5/000086.text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>topic5</td>\n",
       "      <td>../data/t5/000087.text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>topic5</td>\n",
       "      <td>../data/t5/000088.text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>topic5</td>\n",
       "      <td>../data/t5/000089.text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3655</th>\n",
       "      <td>topic2</td>\n",
       "      <td>../data/t5/004995.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3656</th>\n",
       "      <td>topic2</td>\n",
       "      <td>../data/t5/004996.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3657</th>\n",
       "      <td>topic2</td>\n",
       "      <td>../data/t5/004997.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3658</th>\n",
       "      <td>topic2</td>\n",
       "      <td>../data/t5/004998.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3659</th>\n",
       "      <td>topic2</td>\n",
       "      <td>../data/t5/004999.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3249 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     top_topic           absolute_path\n",
       "1       topic5  ../data/t5/000083.text\n",
       "2       topic2  ../data/t5/000086.text\n",
       "3       topic5  ../data/t5/000087.text\n",
       "4       topic5  ../data/t5/000088.text\n",
       "5       topic5  ../data/t5/000089.text\n",
       "...        ...                     ...\n",
       "3655    topic2   ../data/t5/004995.pdf\n",
       "3656    topic2   ../data/t5/004996.pdf\n",
       "3657    topic2   ../data/t5/004997.pdf\n",
       "3658    topic2   ../data/t5/004998.pdf\n",
       "3659    topic2   ../data/t5/004999.pdf\n",
       "\n",
       "[3249 rows x 2 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['top_topic', 'absolute_path']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from sklearn.metrics import pairwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.spatial.distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cityblock', 'cosine', 'euclidean', 'haversine', 'l2', 'l1', 'manhattan', 'precomputed', 'nan_euclidean'])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise.PAIRWISE_DISTANCE_FUNCTIONS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['folder', 'extension', 'filename', 'absolute_path', 'size_mb',\n",
       "       'created_on', 'last_modified_on', 'unix_permission', 'raw_text',\n",
       "       'lemmatized_text', 'stemmed_text', 'top_topic'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Set up LDA with the options we'll keep static\n",
    "model = LatentDirichletAllocation(learning_method='online')\n",
    "\n",
    "# Try all of the options\n",
    "gridsearch = GridSearchCV(model, param_grid=search_params, n_jobs=-1, verbose=1)\n",
    "gridsearch.fit(X_tfidf)\n",
    "\n",
    "# What did we find?\n",
    "print(\"Best Model's Params: \", gridsearch.best_params_)\n",
    "print(\"Best Log Likelihood Score: \", gridsearch.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
