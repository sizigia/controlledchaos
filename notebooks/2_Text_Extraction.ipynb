{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install textract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, stat\n",
    "import re\n",
    "from datetime import datetime\n",
    "import chardet\n",
    "import textract\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/t5/'\n",
    "data_folder = os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {}\n",
    "\n",
    "for ext in {re.search('(\\.\\w+)', file).group(0) for file in data_folder if (file != '.DS_Store')}:\n",
    "    filenames = [f for f in data_folder if f.endswith(ext)]\n",
    "    files[ext] = {\n",
    "        'count': len(filenames),\n",
    "        'filenames': filenames\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.text', 711),\n",
       " ('.xls', 250),\n",
       " ('.html', 1093),\n",
       " ('.jpg', 362),\n",
       " ('.gif', 67),\n",
       " ('.doc', 533),\n",
       " ('.ppt', 368),\n",
       " ('.pdf', 1073)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(key, files[key]['count']) for key in files.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = {key: files[key] for key in files.keys() if (key in ('.jpg', '.gif'))}\n",
    "\n",
    "text = {key: files[key] for key in files.keys() if (key not in ('.jpg', '.gif', '.ppt'))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Extraction — Method Assignment\n",
    "\n",
    "*Images will be ignored on this first iteration.*\n",
    "\n",
    "## Text files\n",
    "\n",
    "| Extension | textract | Python | BeautifulSoup |\n",
    "|:-:|:-:|:-:|:-:|\n",
    "|.xls| x | | |\n",
    "|.pdf| x | | |\n",
    "|.ppt| |||\n",
    "|.doc| x | | |\n",
    "|.html| | | x |\n",
    "|.text| | x | |\n",
    "\n",
    "### .xls files\n",
    "\n",
    "Extraction would be partial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_df = []\n",
    "for ext in text.keys():\n",
    "    ext_df_obj = pd.DataFrame({'folder': ['../data/t5/'] * text[ext]['count'], 'extension': [ext]*text[ext]['count'], 'filename': text[ext]['filenames']})\n",
    "    ext_df.append(ext_df_obj)\n",
    "    \n",
    "text_df = pd.concat(ext_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_df['absolute_path'] = text_df['folder'] + text_df['filename']\n",
    "text_df['size_mb'] = text_df['absolute_path'].apply(lambda row: os.stat(row).st_size / 1e+6)\n",
    "text_df['created_on'] = text_df['absolute_path'].apply(lambda row: datetime.fromtimestamp(os.stat(row).st_birthtime))\n",
    "text_df['last_modified_on'] = text_df['absolute_path'].apply(lambda row: datetime.fromtimestamp(os.stat(row).st_mtime))\n",
    "text_df['unix_permission'] = text_df['absolute_path'].apply(lambda row: stat.filemode(os.stat(row).st_mode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorted by size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder</th>\n",
       "      <th>extension</th>\n",
       "      <th>filename</th>\n",
       "      <th>absolute_path</th>\n",
       "      <th>size_mb</th>\n",
       "      <th>created_on</th>\n",
       "      <th>last_modified_on</th>\n",
       "      <th>unix_permission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>../data/t5/</td>\n",
       "      <td>.xls</td>\n",
       "      <td>000043.xls</td>\n",
       "      <td>../data/t5/000043.xls</td>\n",
       "      <td>14.646272</td>\n",
       "      <td>2011-02-08 15:37:48</td>\n",
       "      <td>2011-02-08 15:37:48</td>\n",
       "      <td>-rw-r--r--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/t5/</td>\n",
       "      <td>.xls</td>\n",
       "      <td>000034.xls</td>\n",
       "      <td>../data/t5/000034.xls</td>\n",
       "      <td>14.257664</td>\n",
       "      <td>2011-02-08 15:37:46</td>\n",
       "      <td>2011-02-08 15:37:46</td>\n",
       "      <td>-rw-r--r--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>../data/t5/</td>\n",
       "      <td>.doc</td>\n",
       "      <td>000113.doc</td>\n",
       "      <td>../data/t5/000113.doc</td>\n",
       "      <td>14.170112</td>\n",
       "      <td>2011-02-08 15:37:54</td>\n",
       "      <td>2011-02-08 15:37:54</td>\n",
       "      <td>-rw-r--r--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>../data/t5/</td>\n",
       "      <td>.xls</td>\n",
       "      <td>000055.xls</td>\n",
       "      <td>../data/t5/000055.xls</td>\n",
       "      <td>14.073344</td>\n",
       "      <td>2011-02-08 15:37:50</td>\n",
       "      <td>2011-02-08 15:37:50</td>\n",
       "      <td>-rw-r--r--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>../data/t5/</td>\n",
       "      <td>.xls</td>\n",
       "      <td>003464.xls</td>\n",
       "      <td>../data/t5/003464.xls</td>\n",
       "      <td>13.533184</td>\n",
       "      <td>2011-02-08 15:53:16</td>\n",
       "      <td>2011-02-08 15:53:16</td>\n",
       "      <td>-rw-r--r--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>../data/t5/</td>\n",
       "      <td>.html</td>\n",
       "      <td>004195.html</td>\n",
       "      <td>../data/t5/004195.html</td>\n",
       "      <td>0.004110</td>\n",
       "      <td>2011-02-08 15:53:52</td>\n",
       "      <td>2011-02-08 15:53:52</td>\n",
       "      <td>-rw-r--r--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>../data/t5/</td>\n",
       "      <td>.html</td>\n",
       "      <td>001532.html</td>\n",
       "      <td>../data/t5/001532.html</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>2009-03-05 16:29:44</td>\n",
       "      <td>2009-03-05 16:29:44</td>\n",
       "      <td>-rw-r--r--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>../data/t5/</td>\n",
       "      <td>.text</td>\n",
       "      <td>002573.text</td>\n",
       "      <td>../data/t5/002573.text</td>\n",
       "      <td>0.004049</td>\n",
       "      <td>2009-03-05 15:59:06</td>\n",
       "      <td>2009-03-05 15:59:06</td>\n",
       "      <td>-rw-r--r--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>../data/t5/</td>\n",
       "      <td>.text</td>\n",
       "      <td>001353.text</td>\n",
       "      <td>../data/t5/001353.text</td>\n",
       "      <td>0.004047</td>\n",
       "      <td>2009-03-05 16:29:32</td>\n",
       "      <td>2009-03-05 16:29:32</td>\n",
       "      <td>-rw-r--r--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/t5/</td>\n",
       "      <td>.doc</td>\n",
       "      <td>000001.doc</td>\n",
       "      <td>../data/t5/000001.doc</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2011-02-08 15:37:40</td>\n",
       "      <td>2020-09-02 12:08:29</td>\n",
       "      <td>-rw-r--r--</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3660 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          folder extension     filename           absolute_path    size_mb  \\\n",
       "11   ../data/t5/      .xls   000043.xls   ../data/t5/000043.xls  14.646272   \n",
       "2    ../data/t5/      .xls   000034.xls   ../data/t5/000034.xls  14.257664   \n",
       "9    ../data/t5/      .doc   000113.doc   ../data/t5/000113.doc  14.170112   \n",
       "23   ../data/t5/      .xls   000055.xls   ../data/t5/000055.xls  14.073344   \n",
       "218  ../data/t5/      .xls   003464.xls   ../data/t5/003464.xls  13.533184   \n",
       "..           ...       ...          ...                     ...        ...   \n",
       "925  ../data/t5/     .html  004195.html  ../data/t5/004195.html   0.004110   \n",
       "291  ../data/t5/     .html  001532.html  ../data/t5/001532.html   0.004109   \n",
       "383  ../data/t5/     .text  002573.text  ../data/t5/002573.text   0.004049   \n",
       "179  ../data/t5/     .text  001353.text  ../data/t5/001353.text   0.004047   \n",
       "0    ../data/t5/      .doc   000001.doc   ../data/t5/000001.doc   0.000000   \n",
       "\n",
       "             created_on    last_modified_on unix_permission  \n",
       "11  2011-02-08 15:37:48 2011-02-08 15:37:48      -rw-r--r--  \n",
       "2   2011-02-08 15:37:46 2011-02-08 15:37:46      -rw-r--r--  \n",
       "9   2011-02-08 15:37:54 2011-02-08 15:37:54      -rw-r--r--  \n",
       "23  2011-02-08 15:37:50 2011-02-08 15:37:50      -rw-r--r--  \n",
       "218 2011-02-08 15:53:16 2011-02-08 15:53:16      -rw-r--r--  \n",
       "..                  ...                 ...             ...  \n",
       "925 2011-02-08 15:53:52 2011-02-08 15:53:52      -rw-r--r--  \n",
       "291 2009-03-05 16:29:44 2009-03-05 16:29:44      -rw-r--r--  \n",
       "383 2009-03-05 15:59:06 2009-03-05 15:59:06      -rw-r--r--  \n",
       "179 2009-03-05 16:29:32 2009-03-05 16:29:32      -rw-r--r--  \n",
       "0   2011-02-08 15:37:40 2020-09-02 12:08:29      -rw-r--r--  \n",
       "\n",
       "[3660 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.sort_values(by='size_mb', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HELPERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(row):\n",
    "    filepath = row['absolute_path']\n",
    "    ext = row['extension']\n",
    "    \n",
    "    return filepath, ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_raw_text(row, thresh=50000):\n",
    "    filepath, ext = process_file(row)\n",
    "    enc = chardet.detect(open(filepath, 'rb').readline())['encoding']\n",
    "    text = ''\n",
    "    \n",
    "    try:\n",
    "        if ext in ('.xls', '.pdf', '.doc'):\n",
    "            text = textract.process(filepath, encoding=enc).decode()\n",
    "        elif ext == '.html':\n",
    "            text = BeautifulSoup(''.join(open(filepath, 'r', encoding=enc).readlines()).lower(), 'html.parser').get_text(separator=' ')\n",
    "        elif ext == '.text':\n",
    "            text = ' '.join(open(filepath, 'r', encoding=enc).readlines())\n",
    "        else:\n",
    "            pass\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if len(text) > thresh:\n",
    "        text = text[:thresh]\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def extract_common_words(text, nwords=1000):\n",
    "    from collections import Counter\n",
    "\n",
    "    words = [w[0] for w in Counter(re.findall('[a-zA-Z]{2,}', text)).most_common(nwords)]\n",
    "    \n",
    "    corpus = ' '.join(words)\n",
    "        \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING *** file size (31309) not 512 + multiple of sector size (512)\n",
      "WARNING *** file size (742989) not 512 + multiple of sector size (512)\n"
     ]
    }
   ],
   "source": [
    "text_df['raw_text'] = text_df.apply(lambda row: extract_raw_text(row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Did the algorithm failed to extract text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([   0,   13,   15,   18,   25,   28,   29,   35,   37,   38,\n",
       "            ...\n",
       "             861,  869,  876,  966,  982,  997, 1002, 1049, 1050, 1057],\n",
       "           dtype='int64', length=411)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df[text_df.raw_text == ''].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text_col = list(text_df.columns).index('raw_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in text_df[text_df.raw_text == ''].index:\n",
    "    text_df.iloc[idx, raw_text_col] = extract_raw_text(text_df.iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df.to_csv('../data/text_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hola\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['hola']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input().split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
